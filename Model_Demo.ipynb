{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNjEfh0EviLlOwoHT241mKv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brianellis1997/Music_Generation/blob/main/Model_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Demo\n",
        "Here we will demo the model (XGBoost) and how it can give popularity predictions for our generative music."
      ],
      "metadata": {
        "id": "oOW4ujkNrJXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/brianellis1997/Music_Generation.git # Clone our repository"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FT8G7QarYLK",
        "outputId": "2b73e042-7869-4112-9548-bd0e6ac5b5dc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Music_Generation'...\n",
            "remote: Enumerating objects: 192, done.\u001b[K\n",
            "remote: Counting objects: 100% (192/192), done.\u001b[K\n",
            "remote: Compressing objects: 100% (181/181), done.\u001b[K\n",
            "remote: Total 192 (delta 95), reused 37 (delta 7), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (192/192), 23.41 MiB | 10.85 MiB/s, done.\n",
            "Resolving deltas: 100% (95/95), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcQxShECrjC6",
        "outputId": "2bc4e36e-0147-44d2-dbe7-f8c7196671b0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IVlnvTLgrAKg"
      },
      "outputs": [],
      "source": [
        "from music21 import *\n",
        "\n",
        "# Load MIDI file\n",
        "midi_file_path = '/content/drive/MyDrive/DS340/Generated_2nd_stage.mid'\n",
        "midi_stream = converter.parse(midi_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraction class\n",
        "class Extraction:\n",
        "    def __init__(self, midi_stream):\n",
        "        self.midi_stream = midi_stream\n",
        "\n",
        "    def key_signature_extract(self):\n",
        "        key_signatures = self.midi_stream.recurse().getElementsByClass(key.KeySignature)\n",
        "        if len(key_signatures) > 0:\n",
        "            key_signature = key_signatures[0]\n",
        "            key_name = key_signature.asKey().tonic.name  # Get the key name (e.g., 'C', 'G#')\n",
        "        else:\n",
        "            key_analysis = self.midi_stream.analyze('key')\n",
        "            key_name = key_analysis.tonic.name  # Get the key name from the analysis\n",
        "\n",
        "        # Define a mapping from key names to Spotify's numbers\n",
        "        key_to_number = {\n",
        "            'C': 0, 'C#': 1, 'D-': 1, 'D': 2, 'D#': 3, 'E-': 3, 'E': 4,\n",
        "            'F': 5, 'F#': 6, 'G-': 6, 'G': 7, 'G#': 8, 'A-': 8,\n",
        "            'A': 9, 'A#': 10, 'B-': 10, 'B': 11\n",
        "        }\n",
        "\n",
        "        # Account for both sharp and flat representations\n",
        "        if key_name in key_to_number:\n",
        "            return key_to_number[key_name]\n",
        "        else:\n",
        "            # Handle the case where the key might be represented differently (e.g., flats)\n",
        "            # music21 might represent some keys differently, e.g., 'F#' could also be 'G-' (G flat)\n",
        "            # This is a placeholder for handling such cases\n",
        "            print(\"Key name not found in mapping:\", key_name)\n",
        "            return None\n",
        "\n",
        "\n",
        "    def tempo_extract(self):\n",
        "        tempos = []\n",
        "        for event in self.midi_stream.flatten():\n",
        "            if 'MetronomeMark' in event.classes:\n",
        "                tempos.append(int(event.number))\n",
        "        if tempos:\n",
        "            return sum(tempos) / len(tempos)\n",
        "        else:\n",
        "            print(\"Tempo information not found in the MIDI file.\")\n",
        "            return None\n",
        "\n",
        "    def duration_extract(self):\n",
        "        quarter_lengths = self.midi_stream.duration.quarterLength\n",
        "        tempo_value = self.tempo_extract()\n",
        "        if tempo_value:  # Ensure tempo_value is not None\n",
        "            duration_min = quarter_lengths / tempo_value\n",
        "            duration_ms = duration_min * 60000  # Convert minutes to milliseconds\n",
        "            return duration_ms\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def valence_extract(self):\n",
        "        major_chords_count = 0\n",
        "        minor_chords_count = 0\n",
        "        chords = self.midi_stream.chordify()\n",
        "        for chord in chords.recurse().getElementsByClass('Chord'):\n",
        "            if chord.isMajorTriad():\n",
        "                major_chords_count += 1\n",
        "            elif chord.isMinorTriad():\n",
        "                minor_chords_count += 1\n",
        "        if major_chords_count > 0:\n",
        "            return major_chords_count / (major_chords_count + minor_chords_count) if minor_chords_count > 0 else 1\n",
        "        return 0\n",
        "\n",
        "    def mode_extract(self):\n",
        "        key = self.key_signature_extract()\n",
        "        key_str = str(key)\n",
        "        if 'major' in key_str:\n",
        "            return 1  # Major mode\n",
        "        else:\n",
        "            return 0  # Minor or other modes\n",
        "\n",
        "    def extract_danceability(self):\n",
        "        # Assuming you've defined tempo_weight, mode_weight, and valence_weight previously\n",
        "        tempo = self.tempo_extract()\n",
        "        mode = self.mode_extract()\n",
        "        valence = self.valence_extract()\n",
        "        tempo_weight = 0.4\n",
        "        mode_weight = 0.3\n",
        "        valence_weight = 0.3\n",
        "        normalized_tempo = min(max((tempo - 60) / (180 - 60), 0), 1) if tempo else 0\n",
        "        danceability_score = (normalized_tempo * tempo_weight) + (mode * mode_weight) + (valence * valence_weight)\n",
        "        return danceability_score\n",
        "\n",
        "    def estimate_energy(self):\n",
        "        avg_tempo = self.tempo_extract()\n",
        "        notes_and_chords = self.midi_stream.recurse().notes\n",
        "        total_duration = self.midi_stream.duration.quarterLength\n",
        "        note_density = len(notes_and_chords) / total_duration if total_duration > 0 else 0\n",
        "        velocities = [n.volume.velocityScalar for n in notes_and_chords if n.volume.velocityScalar is not None]\n",
        "        avg_velocity = sum(velocities) / len(velocities) if velocities else 0.5\n",
        "        energy_score = (avg_tempo / 120) + (note_density * 2) + (avg_velocity * 2)\n",
        "        return min(energy_score / 10, 1.0)\n",
        "\n",
        "    def loudness_extract(self):\n",
        "        # Assuming you want to calculate the average velocity for the normalization process\n",
        "        notes = self.midi_stream.recurse().notes\n",
        "        velocities = [note.volume.velocity for note in notes if note.volume.velocity is not None]\n",
        "\n",
        "        if velocities:\n",
        "            avg_velocity = sum(velocities) / len(velocities)\n",
        "        else:\n",
        "            avg_velocity = 0  # Use a sensible default if no notes are found\n",
        "\n",
        "        # Call the static method correctly using the class name\n",
        "        avg_loudness = self.normalize_loudness(avg_velocity)\n",
        "        return avg_loudness\n",
        "\n",
        "    @staticmethod\n",
        "    def normalize_loudness(velocity, min_loudness=-60, max_loudness=3.855):\n",
        "        # Normalize MIDI velocity from 0-127 to 0-1\n",
        "        normalized_velocity = velocity / 127\n",
        "\n",
        "        # Scale to target loudness range\n",
        "        scaled_loudness = (normalized_velocity * (max_loudness - min_loudness)) + min_loudness\n",
        "\n",
        "        return scaled_loudness"
      ],
      "metadata": {
        "id": "y9onHYFyruNR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Extraction class with the midi_stream\n",
        "extraction = Extraction(midi_stream)\n",
        "\n",
        "# Extract features\n",
        "generated_key = extraction.key_signature_extract()\n",
        "generated_tempo = extraction.tempo_extract()\n",
        "generated_duration = extraction.duration_extract()\n",
        "generated_valence = extraction.valence_extract()\n",
        "generated_mode = extraction.mode_extract()\n",
        "generated_danceability = extraction.extract_danceability()\n",
        "generated_energy = extraction.estimate_energy()\n",
        "generated_loudness = extraction.loudness_extract()\n",
        "\n",
        "# Print extracted features\n",
        "print(\"Key:\", generated_key)\n",
        "print(\"Tempo:\", generated_tempo)\n",
        "print(\"Duration:\", generated_duration)\n",
        "print(\"Valence:\", generated_valence)\n",
        "print(\"Mode:\", generated_mode)\n",
        "print(\"Danceability:\", generated_danceability)\n",
        "print(\"Energy:\", generated_energy)\n",
        "print(\"Loudness:\", generated_loudness)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImZUYSv7sIEP",
        "outputId": "62e2fe85-6c3d-4ea0-97e1-546bca6d292a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Key: 1\n",
            "Tempo: 120.51982378854626\n",
            "Duration: 246930.33116455883\n",
            "Valence: 0.7735849056603774\n",
            "Mode: 0\n",
            "Danceability: 0.4338082176599341\n",
            "Energy: 0.7516624991813022\n",
            "Loudness: -29.48237006159789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model\n",
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "2C4MTGq4r-KU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a model instance\n",
        "loaded_model = xgb.XGBRegressor()\n",
        "\n",
        "# Load the saved model\n",
        "loaded_model.load_model(\"/content/drive/MyDrive/DS340/best_xgb_model.json\")  # Adjust path if necessary"
      ],
      "metadata": {
        "id": "iJSL6Dgcr4Ry"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import joblib  # For loading the scaler\n",
        "\n",
        "# Assuming 'Extraction' is your class for feature extraction\n",
        "class PredictionPipeline:\n",
        "    def __init__(self, model_path, scaler_path):\n",
        "        # Load the XGBoost model\n",
        "        self.model = xgb.XGBRegressor()\n",
        "        self.model.load_model(model_path)\n",
        "\n",
        "        # Load the scaler\n",
        "        self.scaler = joblib.load(scaler_path)\n",
        "\n",
        "        # Initialize the Extraction object (placeholder, need a midi_stream)\n",
        "        self.extraction = None\n",
        "\n",
        "    def extract_features(self, midi_path):\n",
        "        # Load the MIDI file\n",
        "        midi_stream = converter.parse(midi_path)\n",
        "        self.extraction = Extraction(midi_stream)\n",
        "\n",
        "        # Extract features\n",
        "        features = np.array([\n",
        "            self.extraction.valence_extract(),\n",
        "            self.extraction.extract_danceability(),\n",
        "            self.extraction.duration_extract(),\n",
        "            self.extraction.estimate_energy(),\n",
        "            self.extraction.key_signature_extract(),\n",
        "            self.extraction.loudness_extract(),\n",
        "            self.extraction.mode_extract(),\n",
        "            self.extraction.tempo_extract()\n",
        "        ]).reshape(1, -1)  # Reshape for a single sample\n",
        "\n",
        "        return features\n",
        "\n",
        "    def predict(self, midi_path):\n",
        "        # Extract features\n",
        "        features = self.extract_features(midi_path)\n",
        "\n",
        "        # Scale features\n",
        "        features_scaled = self.scaler.transform(features)\n",
        "\n",
        "        # Make prediction\n",
        "        prediction = self.model.predict(features_scaled)\n",
        "\n",
        "        return prediction\n",
        "\n",
        "# Example usage\n",
        "pipeline = PredictionPipeline('/content/drive/MyDrive/DS340/best_xgb_model.json', '/content/drive/MyDrive/DS340/scaler.joblib')\n",
        "prediction = pipeline.predict('/content/drive/MyDrive/DS340/Generated_2nd_stage.mid')\n",
        "print(\"Prediction:\", prediction)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWSU8D2wuKH1",
        "outputId": "8f1bc207-93a5-4bef-b2d1-c41f6c015d8a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: [25.183252]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}