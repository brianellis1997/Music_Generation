{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkOQ6nm5uBKA+KiQ7SwAJ+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brianellis1997/Music_Generation/blob/main/Extraction_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Symbolic Music MIDI (Parent Paper Code)\n",
        "In this notebook, we will demo extracting features from the generated MIDI file produced by our parent paper."
      ],
      "metadata": {
        "id": "5gmQ_4ndXcvh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OE11mDMcqLw2",
        "outputId": "d2cd9e2e-d921-44cd-9fb2-880026626052"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Music_Generation'...\n",
            "remote: Enumerating objects: 162, done.\u001b[K\n",
            "remote: Counting objects: 100% (162/162), done.\u001b[K\n",
            "remote: Compressing objects: 100% (151/151), done.\u001b[K\n",
            "remote: Total 162 (delta 79), reused 36 (delta 7), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (162/162), 3.80 MiB | 7.48 MiB/s, done.\n",
            "Resolving deltas: 100% (79/79), done.\n",
            "/content/Music_Generation\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (6.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.11.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (3.7.1)\n",
            "Collecting miditoolkit (from -r requirements.txt (line 5))\n",
            "  Downloading miditoolkit-1.0.1-py3-none-any.whl (24 kB)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.6.0 (from versions: 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.6.0\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting git+https://github.com/cifkao/fast-transformers.git@39e726864d1a279c9719d33a95868a4ea2fb5ac5\n",
            "  Cloning https://github.com/cifkao/fast-transformers.git (to revision 39e726864d1a279c9719d33a95868a4ea2fb5ac5) to /tmp/pip-req-build-0sa8enr2\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/cifkao/fast-transformers.git /tmp/pip-req-build-0sa8enr2\n",
            "  Running command git rev-parse -q --verify 'sha^39e726864d1a279c9719d33a95868a4ea2fb5ac5'\n",
            "  Running command git fetch -q https://github.com/cifkao/fast-transformers.git 39e726864d1a279c9719d33a95868a4ea2fb5ac5\n",
            "  Running command git checkout -q 39e726864d1a279c9719d33a95868a4ea2fb5ac5\n",
            "  Resolved https://github.com/cifkao/fast-transformers.git to commit 39e726864d1a279c9719d33a95868a4ea2fb5ac5\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from pytorch-fast-transformers==0.3.0) (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-fast-transformers==0.3.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-fast-transformers==0.3.0) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-fast-transformers==0.3.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-fast-transformers==0.3.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-fast-transformers==0.3.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-fast-transformers==0.3.0) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->pytorch-fast-transformers==0.3.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->pytorch-fast-transformers==0.3.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->pytorch-fast-transformers==0.3.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch->pytorch-fast-transformers==0.3.0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch->pytorch-fast-transformers==0.3.0)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->pytorch-fast-transformers==0.3.0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch->pytorch-fast-transformers==0.3.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->pytorch-fast-transformers==0.3.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->pytorch-fast-transformers==0.3.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch->pytorch-fast-transformers==0.3.0)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch->pytorch-fast-transformers==0.3.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->pytorch-fast-transformers==0.3.0) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->pytorch-fast-transformers==0.3.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->pytorch-fast-transformers==0.3.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->pytorch-fast-transformers==0.3.0) (1.3.0)\n",
            "Building wheels for collected packages: pytorch-fast-transformers\n",
            "  Building wheel for pytorch-fast-transformers (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 417, in run\n",
            "    _, build_failures = build(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/wheel_builder.py\", line 320, in build\n",
            "    wheel_file = _build_one(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/wheel_builder.py\", line 194, in _build_one\n",
            "    wheel_path = _build_one_inside_env(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/wheel_builder.py\", line 241, in _build_one_inside_env\n",
            "    wheel_path = build_wheel_legacy(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/build/wheel_legacy.py\", line 83, in build_wheel_legacy\n",
            "    output = call_subprocess(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/subprocess.py\", line 166, in call_subprocess\n",
            "    line: str = proc.stdout.readline()\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 206, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1524, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
            "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 1671, in print\n",
            "    with self:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 864, in __exit__\n",
            "    self._exit_buffer()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 822, in _exit_buffer\n",
            "    self._check_buffer()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 2060, in _check_buffer\n",
            "    self.file.write(text)\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Cloning into 'compose-and-embellish-pop1k7'...\n",
            "remote: Enumerating objects: 3382, done.\u001b[K\n",
            "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 3382 (delta 0), reused 0 (delta 0), pack-reused 3381\u001b[K\n",
            "Receiving objects: 100% (3382/3382), 474.43 KiB | 8.32 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n",
            "Updating files: 100% (3350/3350), done.\n"
          ]
        }
      ],
      "source": [
        "# Clone repository\n",
        "!git clone https://github.com/brianellis1997/Music_Generation.git # Clone our repository\n",
        "!git clone https://github.com/slSeanWU/Compose_and_Embellish.git # Parent Paper's repo\n",
        "%cd Compose_and_Embellish\n",
        "\n",
        "# Install libraries\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# Install pre-trained transformers (15 min runtime)\n",
        "!pip install git+https://github.com/cifkao/fast-transformers.git@39e726864d1a279c9719d33a95868a4ea2fb5ac5\n",
        "!git clone https://huggingface.co/slseanwu/compose-and-embellish-pop1k7\n",
        "!pip install miditoolkit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compose\n",
        "\n",
        "# Generating a leadsheet\n",
        "!python3 stage01_compose/inference.py \\\n",
        "  stage01_compose/config/pop1k7_finetune.yaml \\\n",
        "  generation/stage01 \\\n",
        "  1   # Generate one leadsheet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVCUhqJmPhLc",
        "outputId": "9d3a9dd8-a142-4d5e-fda8-8017d520671b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please input max_bars: 64\n",
            "Please input temperature (randomness): 1.4\n",
            "Please input top_p: 1.3\n",
            "Invalid input. Please enter a valid numeric value.\n",
            "Please input top_p: 2\n",
            "[nucleus parameters] t = 1.4, p = 2\n",
            "[info] # params: 41331059\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Music_Generation/Music_Generation/Music_Generation/stage01_compose/inference.py\", line 131, in <module>\n",
            "    pretrained_dict = torch.load(config['inference_param_path'], map_location='cpu')\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 986, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 435, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/serialization.py\", line 416, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'compose-and-embellish-pop1k7/compose_model_lmd_pretrained_loss0.288.bin'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embellish\n",
        "\n",
        "# We will embellish our generated leadsheet\n",
        "!python3 stage02_embellish/inference.py \\\n",
        "  stage02_embellish/config/pop1k7_default.yaml \\\n",
        "  generation/stage01 \\\n",
        "  generation/stage02"
      ],
      "metadata": {
        "id": "yYkiFDSuXmqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# installs and imports to convert MIDI into audio\n",
        "!pip install pretty_midi\n",
        "!wget https://www.dropbox.com/s/4x27l49kxcwamp5/GeneralUser_GS_1.471.zip\n",
        "!unzip GeneralUser_GS_1.471.zip\n",
        "!apt install -y fluidsynth\n",
        "from pretty_midi import PrettyMIDI\n",
        "from IPython.display import Audio\n",
        "from scipy.io.wavfile import write\n",
        "import librosa"
      ],
      "metadata": {
        "id": "3h0Izl7iYZ2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########\n",
        "# LISTEN #\n",
        "##########\n",
        "\n",
        "# render the first stage\n",
        "!fluidsynth -ni GeneralUser\\ GS\\ 1.471/GeneralUser\\ GS\\ v1.471.sf2 generation/stage01/samp_01.mid -F first_stage.wav -r 44100\n",
        "\n",
        "# render the second stage\n",
        "# !fluidsynth -ni GeneralUser\\ GS\\ 1.471/GeneralUser\\ GS\\ v1.471.sf2 generation/stage02/samp_01_2stage_samp01.mid -F second_stage.wav -r 44100\n",
        "\n",
        "# # uncomment if you want to hear the melody\n",
        "# # generated in the first stage\n",
        "# # hear the first stage\n",
        "x,sr=librosa.load('first_stage.wav')\n",
        "Audio(x,rate=sr)\n",
        "\n",
        "# hear the second stage\n",
        "# x,sr=librosa.load('second_stage.wav')\n",
        "# Audio(x,rate=sr)"
      ],
      "metadata": {
        "id": "A2igEQG5Yamb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extraction\n",
        "Now, we will load in our extraction methods from our extraction features notebook. We will demonstrate how we can extract the necessary features for our regression model from our generated MIDI."
      ],
      "metadata": {
        "id": "EmikBYOjYdeK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gUxerEOYYePS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}